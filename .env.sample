# SF-Bench Environment Variables
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to git (it's in .gitignore)

# ============================================================================
# REQUIRED: AI Provider API Keys
# ============================================================================
# You need at least ONE of these API keys depending on which provider you use

# RouteLLM API Key (for Grok 4.1, GPT-5, Claude Opus 4)
# Get your key from: https://routellm.com
ROUTELLM_API_KEY=your-routellm-api-key-here

# OpenRouter API Key (for Claude Sonnet, GPT-4, Llama, and 100+ models)
# Get your key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your-openrouter-api-key-here

# Google Gemini API Key (for Gemini 2.5 Flash, Gemini Pro)
# Get your key from: https://aistudio.google.com/app/apikey
# Note: GOOGLE_API_KEY or GEMINI_API_KEY (both work)
GOOGLE_API_KEY=your-google-api-key-here
# GEMINI_API_KEY=your-gemini-api-key-here  # Alternative to GOOGLE_API_KEY

# Anthropic API Key (for Claude 3.5 Sonnet, Claude Opus)
# Get your key from: https://console.anthropic.com
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# OpenAI API Key (for GPT-4, GPT-3.5)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# ============================================================================
# OPTIONAL: SF-Bench Configuration
# ============================================================================
# These are optional and have sensible defaults. Only set if you need to override.

# Timeout Configuration (in seconds)
# SF_BENCH_TIMEOUT_SETUP=600      # Timeout for setup phase (scratch org creation, deployment)
# SF_BENCH_TIMEOUT_RUN=300        # Timeout for execution phase (test runs, validation)
# SF_BENCH_TIMEOUT_PATCH=60       # Timeout for patch application
# SF_BENCH_TIMEOUT_GIT=300        # Timeout for Git operations (clone, checkout)
# SF_BENCH_TIMEOUT_API=120        # Timeout for external API calls (AI agents)

# Timeout Multiplier (multiplies all timeouts by this factor)
# Useful for slower networks or systems
# SF_BENCH_TIMEOUT_MULTIPLIER=1.0

# Deterministic Mode (for reproducible evaluations)
# SF_BENCH_DETERMINISTIC_MODE=false  # Set to "true" for deterministic mode
# SF_BENCH_RANDOM_SEED=42            # Random seed for deterministic mode
# SF_BENCH_AI_TEMPERATURE=0.1        # AI model temperature (0.0 for deterministic)

# ============================================================================
# NOTES
# ============================================================================
# 1. DevHub Authentication:
#    - SF-Bench uses Salesforce CLI for DevHub authentication
#    - Run: sf org login web --alias DevHub --set-default-dev-hub
#    - No environment variable needed for DevHub (uses CLI session)
#
# 2. Scratch Org Limits:
#    - Minimum: 1 scratch org (with --max-workers 1)
#    - Recommended: 2-3 scratch orgs (with --max-workers 2-3)
#    - Maximum: 5 scratch orgs (with --max-workers 5)
#
# 3. Token Usage Estimates:
#    - Full evaluation (12 tasks): ~96,000 tokens (~0.1M tokens)
#    - Lite evaluation (5 tasks): ~40,000 tokens
#    - Per task: ~8,000 tokens (input + output + context)
#
# 4. Cost Estimates:
#    - RouteLLM: $0.10-$0.50 per evaluation
#    - OpenRouter: $0.10-$2 per evaluation (varies by model)
#    - Google Gemini: Free tier available
#    - Anthropic: $0.10-$1 per evaluation
#    - OpenAI: $0.50-$2 per evaluation
