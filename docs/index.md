---
layout: default
title: SF-Bench - Salesforce AI Benchmark
description: The open benchmark for evaluating AI coding agents on Salesforce development. Objective measurement, real execution, verified results.
---

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "SF-Bench",
  "alternateName": "Salesforce AI Benchmark",
  "description": "The industry's first comprehensive benchmark for evaluating AI coding agents on Salesforce development. Test Apex, LWC, Flow, Lightning Pages, Experience Cloud, and more with real scratch org execution.",
  "url": "https://yasarshaikh.github.io/SF-bench/",
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Cross-platform",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "author": {
    "@type": "Person",
    "name": "Yasar Shaikh",
    "url": "https://www.linkedin.com/in/yasarshaikh/"
  },
  "codeRepository": "https://github.com/yasarshaikh/SF-bench",
  "keywords": [
    "salesforce benchmark",
    "ai coding agents",
    "salesforce ai",
    "apex testing",
    "lwc testing",
    "flow automation",
    "lightning web components",
    "salesforce development",
    "llm evaluation",
    "ai code generation"
  ],
  "license": "https://github.com/yasarshaikh/SF-bench/blob/main/LICENSE",
  "datePublished": "2024-12-01",
  "dateModified": "2025-12-30",
  "inLanguage": "en-US"
}
</script>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "name": "SF-Bench",
  "url": "https://yasarshaikh.github.io/SF-bench/",
  "description": "The open benchmark for evaluating AI coding agents on Salesforce development",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://yasarshaikh.github.io/SF-bench/?q={search_term_string}",
    "query-input": "required name=search_term_string"
  },
  "publisher": {
    "@type": "Organization",
    "name": "SF-Bench",
    "url": "https://yasarshaikh.github.io/SF-bench/"
  }
}
</script>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "TechArticle",
  "headline": "SF-Bench: The Salesforce AI Benchmark",
  "description": "The open, objective benchmark for measuring AI coding agents on Salesforce development tasks",
  "author": {
    "@type": "Person",
    "name": "Yasar Shaikh"
  },
  "publisher": {
    "@type": "Organization",
    "name": "SF-Bench",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yasarshaikh.github.io/SF-bench/assets/logo.png"
    }
  },
  "datePublished": "2024-12-01",
  "dateModified": "2025-12-30",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yasarshaikh.github.io/SF-bench/"
  },
  "keywords": [
    "salesforce benchmark",
    "ai coding agents",
    "salesforce ai",
    "apex testing",
    "lwc testing",
    "flow automation"
  ]
}
</script>

# SF-Bench: The Salesforce AI Benchmark

**The open, objective benchmark for measuring AI coding agents on Salesforce development tasks.**

---

## ğŸ¯ I Am A...

**Choose your path:**

| ğŸ‘¤ I'm... | ğŸ¯ I Want To... | â¡ï¸ Go To... |
|-----------|-----------------|------------|
| **New to SF-Bench** | Understand what this is | [What is SF-Bench?](getting-started/what-is-sf-bench.html) |
| **New to Salesforce** | Learn about Salesforce | [What is Salesforce?](getting-started/what-is-salesforce.html) |
| **Company/Enterprise** | Evaluate AI tools for my team | [For Companies](personas/for-companies.html) |
| **Salesforce Developer** | Test AI models on Salesforce | [Quick Start](quickstart.html) |
| **Researcher** | Benchmark AI models | [Evaluation Guide](guides/evaluation.html) |
| **SWE-bench User** | Compare with SWE-bench | [Comparison](evaluation/comparison-with-swe-bench.html) |
| **Open Source Enthusiast** | Contribute to SF-Bench | [Contributing](https://github.com/yasarshaikh/SF-bench/blob/main/CONTRIBUTING.md) |
| **Need a Salesforce AI Benchmark?** | Share the story & methodology | [Salesforce AI Benchmark Guide](getting-started/salesforce-ai-benchmark.html) |

---

## ğŸ“Œ Quick Navigation

| I want to... | Link |
|--------------|------|
| ğŸš€ Get started in 5 min | [Quick Start](quickstart.html) |
| ğŸ“£ Understand the Salesforce AI Benchmark | [Salesforce AI Benchmark Guide](getting-started/salesforce-ai-benchmark.html) |
| ğŸ† See results | [Leaderboard](#-leaderboard) |
| ğŸ§ª Test my model | [Testing Your Model](#-testing-your-model) |
| â“ Get help | [FAQ](faq.html) \| [Troubleshooting](guides/troubleshooting.html) |
| â• Add tasks | [Contributing](https://github.com/yasarshaikh/SF-bench/blob/main/CONTRIBUTING.md) |
| ğŸ“Š Submit results | [Submit Results](https://github.com/yasarshaikh/SF-bench/issues/new?template=submit-results.md) |

---

## ğŸ” Salesforce AI Benchmark Overview

The [Salesforce AI Benchmark Guide](getting-started/salesforce-ai-benchmark.html) provides a comprehensive overview of SF-Bench, including:

- **Purpose and methodology**: Why SF-Bench exists and how it works
- **Dataset structure**: How tasks are organized and validated
- **Salesforce-specific validation**: How scoring differs from general coding benchmarks
- **Technical details**: Links to [Evaluation Guide](guides/evaluation.html) and [Validation Methodology](VALIDATION_METHODOLOGY.html)

This guide serves as a central reference for understanding SF-Bench's approach to evaluating AI models on Salesforce development tasks.

---

## ğŸ¯ What We Do

SF-Bench **measures and reports**. We don't predict or claim expected outcomes.

| We Do | We Don't |
|-------|----------|
| âœ… Measure actual performance | âŒ Predict success rates |
| âœ… Report objective results | âŒ Claim what models "should" score |
| âœ… Verify functional outcomes | âŒ Interpret or editorialize |
| âœ… Test in real Salesforce orgs | âŒ Just check syntax |

---

## ğŸ† Leaderboard

*December 2025*

| Rank | Model | Overall | Functional Score | LWC | Deploy | Apex | Flow | Lightning Pages | Experience Cloud | Architecture |
|:----:|-------|:-------:|:----------------:|:---:|:------:|:----:|:----:|:---------------:|:----------------:|:------------:|
| ğŸ¥‡ | **Claude Sonnet 4.5** | **41.67%** | **6.0%** | 100% | 100% | 100% | 0%* | 0% | 0% | 0% |
| ğŸ¥ˆ | **Gemini 2.5 Flash** | **25.0%** | - | 100% | 100% | 0%* | 0%* | 0% | 0% | 0% |
| - | *More results pending* | -% | - | -% | -% | -% | -% | -% | -% | -% |

*\* Flow tasks failed due to scratch org creation issues (being fixed)*

> **Note**: Functional Score (0-100) uses weighted validation. See [VALIDATION_METHODOLOGY.md](VALIDATION_METHODOLOGY.html) for details.

**[Full Leaderboard â†’](LEADERBOARD.html)**

---

## ğŸ§ª Testing Your Model

### Supported Providers

| Provider | Models | Setup |
|----------|--------|-------|
| **OpenRouter** | 100+ models | `OPENROUTER_API_KEY` |
| **RouteLLM** | Gemini 3, Grok, GPT-5 | `ROUTELLM_API_KEY` |
| OpenAI | GPT-4, GPT-3.5 | `OPENAI_API_KEY` |
| Anthropic | Claude 3.5, 3 | `ANTHROPIC_API_KEY` |
| Google | Gemini 2.5, Pro | `GOOGLE_API_KEY` |
| Ollama | Local models | No key needed |

### Quick Start

```bash
git clone https://github.com/yasarshaikh/SF-bench.git
cd SF-bench
pip install -e .

# Run with OpenRouter (access to all models)
export OPENROUTER_API_KEY="your-key"
python scripts/evaluate.py --model anthropic/claude-3.5-sonnet

# Run with Gemini
export GOOGLE_API_KEY="your-key"
python scripts/evaluate.py --model gemini-2.5-flash

# Run with local Ollama
python scripts/evaluate.py --model codellama --provider ollama
```

---

## ğŸ”§ How Validation Works

### We Check Outcomes, Not Just Deployment

```
Standard Benchmark:
  Deploy succeeded? â†’ PASS âœ…
  
SF-Bench:
  Deploy succeeded? â†’ Step 1 of 3
  Tests passed? â†’ Step 2 of 3
  Business outcome achieved? â†’ Step 3 of 3 â†’ PASS/FAIL
```

### Example: Flow Task

```bash
# Step 1: Deploy
sf project deploy start  # âœ…

# Step 2: Create test data
sf apex run -c "insert new Account(Name='Test', Type='Customer');"

# Step 3: Verify outcome
sf data query -q "SELECT Id FROM Task WHERE WhatId = :accId"
# 1 Task created â†’ PASS
# 0 Tasks â†’ FAIL (Flow didn't work)
```

---

## ğŸ“Š Task Categories

SF-Bench includes **12 verified tasks** across Salesforce development domains:

| Category | Tasks | Description | Lite Dataset |
|----------|:-----:|-------------|:------------:|
| **Apex** | 2 | Triggers, Classes, Integrations | âœ… |
| **LWC** | 2 | Lightning Components | âœ… |
| **Flow** | 2 | Record-Triggered Flows, Invocable Actions | âœ… |
| **Lightning Pages** | 1 | Dynamic Forms | âœ… |
| **Experience Cloud** | 1 | Guest Access | âŒ |
| **Architecture** | 4 | Full-stack Design | âœ… |

### Datasets

- **Lite (5 tasks):** Quick validation in ~10 minutes - [data/tasks/lite.json](https://github.com/yasarshaikh/SF-bench/blob/main/data/tasks/lite.json)
- **Verified (12 tasks):** Full evaluation in ~1 hour - [data/tasks/verified.json](https://github.com/yasarshaikh/SF-bench/blob/main/data/tasks/verified.json)
- **Realistic:** Challenging scenarios - [data/tasks/realistic.json](https://github.com/yasarshaikh/SF-bench/blob/main/data/tasks/realistic.json)

---

## ğŸ“– Documentation

### Getting Started
- ğŸš€ [Quick Start Guide](quickstart.html) - Get running in 5 minutes
- ğŸ“š [What is SF-Bench?](getting-started/what-is-sf-bench.html) - Complete overview
- ğŸ¢ [What is Salesforce?](getting-started/what-is-salesforce.html) - For beginners
- â“ [FAQ](faq.html) - Common questions and answers
- ğŸ”§ [Troubleshooting](guides/troubleshooting.html) - Common issues and solutions

### For Different Audiences
- ğŸ’¼ [For Companies](personas/for-companies.html) - Business case & ROI
- ğŸ‘¨â€ğŸ’» [For Salesforce Developers](guides/evaluation.html) - Evaluation guide
- ğŸ”¬ [For Researchers](VALIDATION_METHODOLOGY.html) - Methodology details
- ğŸ”„ [SWE-bench Comparison](evaluation/comparison-with-swe-bench.html) - Benchmark comparison

### Reference
- ğŸ“‹ [Validation Methodology](VALIDATION_METHODOLOGY.html) - How we validate results
- ğŸ“Š [Benchmark Details](BENCHMARK.html) - Technical specifications
- ğŸ† [Full Leaderboard](LEADERBOARD.html) - Complete model rankings
- ğŸ“ˆ [Evaluation Guide](guides/evaluation.html) - Complete evaluation guide
- ğŸ“„ [Result Schema](reference/result-schema.html) - Result format reference

### Contributing
- â• [Contributing Guide](https://github.com/yasarshaikh/SF-bench/blob/main/CONTRIBUTING.md)
- ğŸ¯ [Task Guidelines](https://github.com/yasarshaikh/SF-bench/blob/main/CONTRIBUTING.md#adding-tasks) - Creating new tasks
- ğŸ“Š [Submitting Results](https://github.com/yasarshaikh/SF-bench/issues/new?template=submit-results.md)

---

## ğŸ¤ Get Involved

| Action | Link |
|--------|------|
| â­ Star the repo | [GitHub](https://github.com/yasarshaikh/SF-bench) |
| ğŸ“Š Submit results | [Submit](https://github.com/yasarshaikh/SF-bench/issues/new?template=submit-results.md) |
| ğŸ› Report bugs | [Issues](https://github.com/yasarshaikh/SF-bench/issues) |
| â• Add tasks | [Contributing](https://github.com/yasarshaikh/SF-bench/blob/main/CONTRIBUTING.md) |

---

**â­ Star us on GitHub if you find SF-Bench useful!**
